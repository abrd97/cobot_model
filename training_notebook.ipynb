{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision numpy pandas scikit-learn matplotlib opencv-python onnx onnxruntime termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "import cv2\n",
    "from shutil import copy2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pandas as pd\n",
    "from termcolor import colored \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'cut/images'\n",
    "label_dir = 'cut/labels'\n",
    "output_dirs = {\n",
    "    'train': 'cut/split/train',\n",
    "    'val': 'cut/split/val',\n",
    "    'test': 'cut/split/test'\n",
    "}\n",
    "\n",
    "for path in output_dirs.values():\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n",
    "label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
    "\n",
    "# Sort to make sure images and labels are matched\n",
    "image_files.sort()\n",
    "label_files.sort()\n",
    "\n",
    "assert len(image_files) == len(label_files), \"Mismatch between number of images and labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Label and create DataFrame\n",
    "def read_label(label_file):\n",
    "    with open(os.path.join(label_dir, label_file), 'r') as f:\n",
    "        label = int(f.read().strip())\n",
    "    return label\n",
    "\n",
    "data = []\n",
    "for img_file, lbl_file in zip(image_files, label_files):\n",
    "    label = read_label(lbl_file)\n",
    "    data.append({'image': img_file, 'labels': label})\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sample of data frame \n",
    "print(df.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy files to corresponding directories\n",
    "def copy_files(df, split):\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = os.path.join(image_dir, row['image'])\n",
    "        dest_path = os.path.join(output_dirs[split], row['image'])\n",
    "        copy2(img_path, dest_path)\n",
    "\n",
    "copy_files(train_df, 'train')\n",
    "copy_files(val_df, 'val')\n",
    "copy_files(test_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data preparation\n",
    "def count_files(dir_path):\n",
    "    return len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])\n",
    "\n",
    "print(f\"Training images: {count_files(output_dirs['train'])}\")\n",
    "print(f\"Validation images: {count_files(output_dirs['val'])}\")\n",
    "print(f\"Test images: {count_files(output_dirs['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image\n",
    "random_file = random.choice(os.listdir(output_dirs['train']))\n",
    "image = cv2.imread(os.path.join(\"cut\", \"split\", \"train\", random_file))\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = os.path.join(self.image_dir, self.dataframe.iloc[idx, 0])\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "        label = int(self.dataframe.iloc[idx, 1:])\n",
    "        label = torch.tensor(label, dtype=torch.int8)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define transformations for the training and validation data\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(dataframe=train_df, image_dir=output_dirs['train'], transform=transform)\n",
    "val_dataset = CustomDataset(dataframe=val_df, image_dir=output_dirs['val'], transform=transform)\n",
    "test_dataset = CustomDataset(dataframe=test_df, image_dir=output_dirs['test'], transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# model.classifier[1] = nn.Sequential(\n",
    "#     nn.Linear(model.classifier[1].in_features, 1),\n",
    "#     nn.Sigmoid()\n",
    "# )\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.to(device)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1)  # Outputs raw logits (not passed through sigmoid)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model with Early Stopping for Binary Classification (1 output neuron with Sigmoid)\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20, patience=5):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device) \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).squeeze()  # Forward pass and remove extra dimensions\n",
    "            \n",
    "            loss = criterion(outputs, labels.float())  # Ensure labels are float for BCEWithLogitsLoss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs).squeeze()\n",
    "                \n",
    "                loss = criterion(outputs, labels.float())\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "                val_preds.extend((preds > 0.5).astype(int))  # Convert probabilities to binary predictions\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_accuracy = np.mean(np.equal(np.array(val_preds), np.array(val_labels)))\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(epoch_val_accuracy)\n",
    "                \n",
    "        # Early stopping\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            \n",
    "            # Save the best model as .pth\n",
    "            torch.save(model.state_dict(), 'model/best_model_new.pth')\n",
    "            \n",
    "            # Save the best model as ONNX\n",
    "            example_input = torch.randn(1, 3, 117, 112).to(device)  # Example input for ONNX export\n",
    "            torch.onnx.export(model,\n",
    "                              example_input,                         # Model input\n",
    "                              'model/best_model_new.onnx',           # File to save the ONNX model\n",
    "                              export_params=True,                    # Store the trained weights\n",
    "                              opset_version=11,                      # ONNX version\n",
    "                              input_names=['input'],                 # Input name for ONNX\n",
    "                              output_names=['output'],               # Output name for ONNX\n",
    "                              dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})  # Allow variable batch size\n",
    "            \n",
    "            print(f\"Best model saved at epoch {epoch+1}\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f'Early stopping triggered after {epoch + 1} epochs without improvement')\n",
    "            break\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"Training Loss: {epoch_loss:.4f}, \"\n",
    "              f\"Validation Loss: {epoch_val_loss:.4f}, \"\n",
    "              f\"Validation Accuracy: {epoch_val_accuracy:.4f}\")\n",
    "    \n",
    "    return train_losses, val_losses, val_accuracies\n",
    "\n",
    "train_losses, val_losses, val_accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(train_losses, val_losses, val_accuracies):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, 'ro-', label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, val_accuracies, 'go-', label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(train_losses, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16519/3414121902.py:13: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  label = int(self.dataframe.iloc[idx, 1:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: \u001b[32m0.3228\u001b[0m, Accuracy: \u001b[32m0.9798\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_model(model, test_loader, criterion, accuracy_threshold=0.8, loss_threshold=0.5):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs).squeeze(1)  # Ensure the output shape matches the labels\n",
    "            \n",
    "            loss = criterion(outputs, labels.float())  # Ensure labels are float for BCEWithLogitsLoss\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Apply sigmoid to convert logits to probabilities for binary classification\n",
    "            test_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    \n",
    "    test_preds_binary = (np.array(test_preds) > 0.5).astype(int)\n",
    "    \n",
    "    test_accuracy = np.mean(np.equal(test_preds_binary, np.array(test_labels)))\n",
    "    \n",
    "    if test_accuracy >= accuracy_threshold:\n",
    "        accuracy_display = colored(f'{test_accuracy:.4f}', 'green')\n",
    "    else:\n",
    "        accuracy_display = colored(f'{test_accuracy:.4f}', 'red')\n",
    "    \n",
    "    if test_loss <= loss_threshold:\n",
    "        loss_display = colored(f'{test_loss:.4f}', 'green')\n",
    "    else:\n",
    "        loss_display = colored(f'{test_loss:.4f}', 'red')\n",
    "    \n",
    "    print(f'Test Loss: {loss_display}, Accuracy: {accuracy_display}')\n",
    "\n",
    "evaluate_model(model, test_loader, criterion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aaa37d-8963-4e1a-9aa2-25947d45537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d28737-a776-40ef-9445-652ec17c44c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745bcd83-ce11-486e-8931-909cd0a005ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install first all dependencies\n",
    "!pip install torch torchvision numpy pandas scikit-learn matplotlib skorch opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af6acbb-f4ba-484b-b22f-a8b8ded423ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all needed modules\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copy2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f93ffa-a99c-4d5c-93d4-c75fc7180607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path and load data\n",
    "image_dir = 'gt/images'\n",
    "label_dir = 'gt/labels'\n",
    "output_dirs = {\n",
    "    'train': 'split/train',\n",
    "    'val': 'split/val',\n",
    "    'test': 'split/test'\n",
    "}\n",
    "\n",
    "# Ensure output directories exist\n",
    "for path in output_dirs.values():\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# List all images and corresponding label files\n",
    "image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n",
    "label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
    "\n",
    "# Sort to make sure images and labels are matched\n",
    "image_files.sort()\n",
    "label_files.sort()\n",
    "\n",
    "# Check if we have a matching number of image and label files\n",
    "assert len(image_files) == len(label_files), \"Mismatch between number of images and labels\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7376ed-39b6-41aa-97f1-fa7ec05a768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Label and create DataFrame\n",
    "def read_labels(label_file):\n",
    "    with open(os.path.join(label_dir, label_file), 'r') as f:\n",
    "        labels = list(map(int, f.read().strip().split(',')))\n",
    "    return labels\n",
    "\n",
    "data = []\n",
    "for img_file, lbl_file in zip(image_files, label_files):\n",
    "    labels = read_labels(lbl_file)\n",
    "    data.append({'image': img_file, 'labels': labels})\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823399d-9fcd-4393-8ac5-3863ae515744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Check the number of samples in each split\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sample of data frame \n",
    "print(df.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d095ffc-b9c1-43d7-8971-893582fd8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy files to corresponding directories\n",
    "def copy_files(df, split):\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = os.path.join(image_dir, row['image'])\n",
    "        dest_path = os.path.join(output_dirs[split], row['image'])\n",
    "        copy2(img_path, dest_path)\n",
    "\n",
    "# Copy files for each split\n",
    "copy_files(train_df, 'train')\n",
    "copy_files(val_df, 'val')\n",
    "copy_files(test_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fe5cf-84ab-43c5-ba86-a45c89c99d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data preparation\n",
    "# Function to count files in directories\n",
    "def count_files(dir_path):\n",
    "    return len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])\n",
    "\n",
    "# Verify counts\n",
    "print(f\"Training images: {count_files(output_dirs['train'])}\")\n",
    "print(f\"Validation images: {count_files(output_dirs['val'])}\")\n",
    "print(f\"Test images: {count_files(output_dirs['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b0060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show resized image\n",
    "random_file = random.choice(os.listdir(output_dirs['train']))\n",
    "image = cv2.imread(os.path.join(\"split\", \"train\", random_file))\n",
    "resized =  cv2.cvtColor(cv2.resize(image, (224, 224)), cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(resized)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e78b7-132d-454a-bc45-9756c24d3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data set class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.dataframe.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        labels = np.array(self.dataframe.iloc[idx, 1:].values[0])\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        # Squeeze labels to ensure the correct shape [num_outputs]\n",
    "        labels = labels.squeeze()\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, labels\n",
    "\n",
    "# Define transformations for the training and validation data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to fit ResNet input\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust brightness, contrast, etc.\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random affine transformation with translation\n",
    "    transforms.ToTensor(),  # Convert images to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet stats\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(dataframe=train_df, image_dir=output_dirs['train'], transform=transform)\n",
    "val_dataset = CustomDataset(dataframe=val_df, image_dir=output_dirs['val'], transform=transform)\n",
    "test_dataset = CustomDataset(dataframe=test_df, image_dir=output_dirs['test'], transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca36bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified ResNet model\n",
    "class ResNetWithSigmoid(nn.Module):\n",
    "    def __init__(self, num_outputs = 15):\n",
    "        super(ResNetWithSigmoid, self).__init__()\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(self.base_model.fc.in_features, num_outputs),\n",
    "            nn.Sigmoid()  # Ensure the outputs are between 0 and 1\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef845e8-985a-4cc6-9fc5-d1e4979898b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model\n",
    "model = ResNetWithSigmoid()\n",
    "\n",
    "# Define the parameter grid\n",
    "# params = {\n",
    "#     'lr': [0.001, 0.01, 0.1],\n",
    "#     'max_epochs': [30],\n",
    "#     'optimizer_weight_decay': [0.01, 0.001, 0.0001],\n",
    "#     'batch_size': [8, 16, 32],\n",
    "# }\n",
    "\n",
    "# Move model to GPU if available\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40c8af5-1a66-4a37-b86e-da2bec5d83a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model with early stopping\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20, patience=5):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            print(outputs[0].shape)\n",
    "            print(outputs[0])\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_accuracy = np.mean(np.equal((np.array(val_preds) > 0.5).astype(int), np.array(val_labels)))\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(epoch_val_accuracy)\n",
    "                \n",
    "        # Early stopping\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), 'model/best_model.pth')\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f'Early stopping triggered after {epoch + 1} epochs without improvement')\n",
    "            break\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"Training Loss: {epoch_loss:.4f}, \"\n",
    "              f\"Validation Loss: {epoch_val_loss:.4f}, \"\n",
    "              f\"Validation Accuracy: {epoch_val_accuracy:.4f}\")\n",
    "        \n",
    "    \n",
    "    return train_losses, val_losses, val_accuracies\n",
    "\n",
    "# Train the model with early stopping\n",
    "train_losses, val_losses, val_accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50, patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc88a4-f85b-4114-b6a2-33a600a70089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(train_losses, val_losses, val_accuracies):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, 'ro-', label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, val_accuracies, 'go-', label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(train_losses, val_losses, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51be6ff-b486-4944-9132-07be80ad9774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            test_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "            test_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_accuracy = np.mean(np.equal((np.array(test_preds) > 0.5).astype(int), np.array(test_labels)))\n",
    "    \n",
    "    print(f'Test Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, test_loader, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
